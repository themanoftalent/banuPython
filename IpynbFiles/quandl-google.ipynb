{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-05T10:11:06.258798Z","iopub.execute_input":"2022-11-05T10:11:06.259203Z","iopub.status.idle":"2022-11-05T10:11:06.266800Z","shell.execute_reply.started":"2022-11-05T10:11:06.259172Z","shell.execute_reply":"2022-11-05T10:11:06.265477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The import statement <br>\nimport_stmt     ::=  \"import\" module [\"as\" name] ( \",\" module [\"as\" name] )*\n                     | \"from\" relative_module \"import\" identifier [\"as\" name]\n                     ( \",\" identifier [\"as\" name] )*\n                     | \"from\" relative_module \"import\" \"(\" identifier [\"as\" name]\n                     ( \",\" identifier [\"as\" name] )* [\",\"] \")\"\n                     | \"from\" module \"import\" \"*\"\nmodule          ::=  (identifier \".\")* identifier\nrelative_module ::=  \".\"* module | \".\"+\nname            ::=  identifier\n\nThe basic import statement (no from clause) is executed in two steps:\nfind a module, loading and initializing it if necessary\ndefine a name or names in the local namespace for the scope where the import statement occurs.\nWhen the statement contains multiple clauses (separated by commas) the two steps are carried out separately for each clause, just as though the clauses had been separated out into individiual import statements.\nThe details of the first step, finding and loading modules are described in greater detail in the section on the import system, which also describes the various types of packages and modules that can be imported, as well as all the hooks that can be used to customize the import system. Note that failures in this step may indicate either that the module could not be located, or that an error occurred while initializing the module, which includes execution of the module’s code.\nIf the requested module is retrieved successfully, it will be made available in the local namespace in one of three ways:","metadata":{}},{"cell_type":"code","source":"# importing libraries Kütüphaneleri çağırma/ yükleme\nimport pandas as pd #Dataframe\nimport quandl #quandl verileri topladım\nimport math #matematiksel işlemler\nfrom sklearn import preprocessing, svm #önişlem, destek vektör makineleri çağırdım\nfrom sklearn.linear_model import LinearRegression #linear model veri CSV (excel) \nimport numpy as np #matematiksel array\nfrom matplotlib import style #grafikler için\nstyle.use('fivethirtyeight') #bu matplotlkibe ait\nfrom sklearn.model_selection import train_test_split #veriyi bölmek cross_validaition, cross_validation kullanımdan kaldırılmıştır. ","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:49:59.701252Z","iopub.execute_input":"2022-11-05T10:49:59.701627Z","iopub.status.idle":"2022-11-05T10:49:59.708124Z","shell.execute_reply.started":"2022-11-05T10:49:59.701597Z","shell.execute_reply":"2022-11-05T10:49:59.707182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cross_validation is deprecated since version 0.18. This module will be removed in 0.20.\n\nUse sklearn.model_selection.train_test_split instead.\n\nfrom sklearn.model_selection import train_test_split\n<br>\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n/tmp/ipykernel_28/852433834.py in <module>\n      3 import quandl\n      4 import math\n----> 5 from sklearn import preprocessing, cross_validation, svm\n      6 from sklearn.linear_model import LinearRegression\n      7 import numpy as np\n\nImportError: cannot import name 'cross_validation' from 'sklearn' (/opt/conda/lib/python3.7/site-packages/sklearn/__init__.py)","metadata":{}},{"cell_type":"code","source":"# pip install quandl","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:50:12.850898Z","iopub.execute_input":"2022-11-05T10:50:12.851625Z","iopub.status.idle":"2022-11-05T10:50:12.856606Z","shell.execute_reply.started":"2022-11-05T10:50:12.851582Z","shell.execute_reply":"2022-11-05T10:50:12.855363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import quandl","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:11:17.228733Z","iopub.execute_input":"2022-11-05T10:11:17.229119Z","iopub.status.idle":"2022-11-05T10:11:17.234727Z","shell.execute_reply.started":"2022-11-05T10:11:17.229081Z","shell.execute_reply":"2022-11-05T10:11:17.233428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting data from quandl\ndf = quandl.get(\"WIKI/GOOGL\")\n# print(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:52:02.020752Z","iopub.execute_input":"2022-11-05T10:52:02.021212Z","iopub.status.idle":"2022-11-05T10:52:04.553378Z","shell.execute_reply.started":"2022-11-05T10:52:02.021174Z","shell.execute_reply":"2022-11-05T10:52:04.552214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pd = pd.DataFrame(df)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:52:04.555329Z","iopub.execute_input":"2022-11-05T10:52:04.555693Z","iopub.status.idle":"2022-11-05T10:52:04.560822Z","shell.execute_reply.started":"2022-11-05T10:52:04.555661Z","shell.execute_reply":"2022-11-05T10:52:04.559891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pd.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:52:31.403368Z","iopub.execute_input":"2022-11-05T10:52:31.403791Z","iopub.status.idle":"2022-11-05T10:52:31.430783Z","shell.execute_reply.started":"2022-11-05T10:52:31.403757Z","shell.execute_reply":"2022-11-05T10:52:31.429690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfpd.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:53:00.511326Z","iopub.execute_input":"2022-11-05T10:53:00.512091Z","iopub.status.idle":"2022-11-05T10:53:00.560694Z","shell.execute_reply.started":"2022-11-05T10:53:00.512053Z","shell.execute_reply":"2022-11-05T10:53:00.559239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfpd.columns","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:54:28.455779Z","iopub.execute_input":"2022-11-05T10:54:28.456151Z","iopub.status.idle":"2022-11-05T10:54:28.463513Z","shell.execute_reply.started":"2022-11-05T10:54:28.456121Z","shell.execute_reply":"2022-11-05T10:54:28.462348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.keys() #özellikleri görme","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:11:19.964474Z","iopub.execute_input":"2022-11-05T10:11:19.964858Z","iopub.status.idle":"2022-11-05T10:11:19.974590Z","shell.execute_reply.started":"2022-11-05T10:11:19.964823Z","shell.execute_reply":"2022-11-05T10:11:19.973452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pd.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:54:59.028273Z","iopub.execute_input":"2022-11-05T10:54:59.028665Z","iopub.status.idle":"2022-11-05T10:54:59.036927Z","shell.execute_reply.started":"2022-11-05T10:54:59.028633Z","shell.execute_reply":"2022-11-05T10:54:59.035747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pd.size","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:55:17.952512Z","iopub.execute_input":"2022-11-05T10:55:17.952904Z","iopub.status.idle":"2022-11-05T10:55:17.961065Z","shell.execute_reply.started":"2022-11-05T10:55:17.952873Z","shell.execute_reply":"2022-11-05T10:55:17.959569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the features we need from the dataframe and dropping the ones we don't need\n# Veri dataframe ihtiyacımız olan özellikleri almak ve ihtiyacımız olmayanları atmak\n\ndf = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Ex-Dividend', 'Split Ratio','Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume' ]]","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:59:29.552519Z","iopub.execute_input":"2022-11-05T10:59:29.552997Z","iopub.status.idle":"2022-11-05T10:59:29.560772Z","shell.execute_reply.started":"2022-11-05T10:59:29.552949Z","shell.execute_reply":"2022-11-05T10:59:29.559596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pca","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:58:52.767365Z","iopub.execute_input":"2022-11-05T10:58:52.767798Z","iopub.status.idle":"2022-11-05T10:58:52.772639Z","shell.execute_reply.started":"2022-11-05T10:58:52.767766Z","shell.execute_reply":"2022-11-05T10:58:52.771713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the features we need from the data frame and dropping the ones we don't need\n# ihtiyacımız olmayan özellikleri atmak\n\ndf[\"HL_PCT\"] = (df[\"High\"] - df[\"Close\"]) / df[\"Close\"] * 100.0 #normalization 0-1\ndf[\"PCT_change\"] = (df[\"Close\"] - df[\"Open\"]) / df[\"Open\"] * 100.0","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:02:57.203676Z","iopub.execute_input":"2022-11-05T11:02:57.204102Z","iopub.status.idle":"2022-11-05T11:02:57.215821Z","shell.execute_reply.started":"2022-11-05T11:02:57.204068Z","shell.execute_reply":"2022-11-05T11:02:57.214911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['Close', 'HL_PCT', 'PCT_change', 'Volume']]\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:03:08.224818Z","iopub.execute_input":"2022-11-05T11:03:08.225251Z","iopub.status.idle":"2022-11-05T11:03:08.235562Z","shell.execute_reply.started":"2022-11-05T11:03:08.225215Z","shell.execute_reply":"2022-11-05T11:03:08.234760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pd.head(4)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:04:49.381658Z","iopub.execute_input":"2022-11-05T11:04:49.382050Z","iopub.status.idle":"2022-11-05T11:04:49.403222Z","shell.execute_reply.started":"2022-11-05T11:04:49.382020Z","shell.execute_reply":"2022-11-05T11:04:49.401888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the label column and the features column and dropping the NaN values\n# Etiket sütununu ve özellikler sütununu tanımlama ve NaN değerlerini düşürme\n\nforecast_col = 'Close'  # label column for prediction (y)\ndf.fillna(-99999, inplace=True)  # fill missing data with outlier value\n\nforecast_out = int(math.ceil(0.01 * len(df)))  # 1% of the length of the dataframe\ndf['label'] = df[forecast_col].shift(-forecast_out)  # shift the label column up by forecast_out\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:07:10.744264Z","iopub.execute_input":"2022-11-05T11:07:10.744701Z","iopub.status.idle":"2022-11-05T11:07:10.758217Z","shell.execute_reply.started":"2022-11-05T11:07:10.744664Z","shell.execute_reply":"2022-11-05T11:07:10.757000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0/1\n# defining the features and the label and dropping the NaN values from the features\nX = np.array(df.drop(['label'], 1))  # features (X)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:10:05.545745Z","iopub.execute_input":"2022-11-05T11:10:05.546128Z","iopub.status.idle":"2022-11-05T11:10:05.554741Z","shell.execute_reply.started":"2022-11-05T11:10:05.546096Z","shell.execute_reply":"2022-11-05T11:10:05.553370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:12:04.118128Z","iopub.execute_input":"2022-11-05T11:12:04.118556Z","iopub.status.idle":"2022-11-05T11:12:04.125617Z","shell.execute_reply.started":"2022-11-05T11:12:04.118523Z","shell.execute_reply":"2022-11-05T11:12:04.124393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.size- X.size","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:11:40.385027Z","iopub.execute_input":"2022-11-05T11:11:40.385445Z","iopub.status.idle":"2022-11-05T11:11:40.392445Z","shell.execute_reply.started":"2022-11-05T11:11:40.385411Z","shell.execute_reply":"2022-11-05T11:11:40.391503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:14:00.898970Z","iopub.execute_input":"2022-11-05T11:14:00.899420Z","iopub.status.idle":"2022-11-05T11:14:00.904631Z","shell.execute_reply.started":"2022-11-05T11:14:00.899381Z","shell.execute_reply":"2022-11-05T11:14:00.903701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = preprocessing.scale(X)  # scale the features\nX_lately = X[-forecast_out:]  # features for the last forecast_out rows\nX = X[:-forecast_out]  # features for all rows except the last forecast_out rows\ndf.dropna(inplace=True)  # drop the rows with missing data","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:12:28.200355Z","iopub.execute_input":"2022-11-05T11:12:28.200763Z","iopub.status.idle":"2022-11-05T11:12:28.212262Z","shell.execute_reply.started":"2022-11-05T11:12:28.200732Z","shell.execute_reply":"2022-11-05T11:12:28.210851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label(close) test \ny = np.array(df['label'])  # labels (y)\nlen(y)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:14:09.713123Z","iopub.execute_input":"2022-11-05T11:14:09.713532Z","iopub.status.idle":"2022-11-05T11:14:09.723328Z","shell.execute_reply.started":"2022-11-05T11:14:09.713500Z","shell.execute_reply":"2022-11-05T11:14:09.722089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the data into training and testing data\n# veriyi bölme\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=100)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:16:30.067410Z","iopub.execute_input":"2022-11-05T11:16:30.067829Z","iopub.status.idle":"2022-11-05T11:16:30.074567Z","shell.execute_reply.started":"2022-11-05T11:16:30.067795Z","shell.execute_reply":"2022-11-05T11:16:30.073228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model oluştur\n#model eğitirken train (X_train ,y_train)\n\nclf = LinearRegression()  # n_jobs=-1 means use all available threads\nclf.fit(X_train, y_train) # training the model with the training data  model eğitimi","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:20:06.416003Z","iopub.execute_input":"2022-11-05T11:20:06.417079Z","iopub.status.idle":"2022-11-05T11:20:06.426699Z","shell.execute_reply.started":"2022-11-05T11:20:06.417036Z","shell.execute_reply":"2022-11-05T11:20:06.425546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = clf.score(X_test, y_test) # R^2 coefficient of determination, 1 is perfect prediction and 0 is no prediction at all (confidence)\nprint(f\"Doğruluk oranı (Accuracy) %.2f\" % accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:21:36.590534Z","iopub.execute_input":"2022-11-05T11:21:36.590952Z","iopub.status.idle":"2022-11-05T11:21:36.598046Z","shell.execute_reply.started":"2022-11-05T11:21:36.590919Z","shell.execute_reply":"2022-11-05T11:21:36.597062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the stock price for the next forecast_out days\n\nforecast_set = clf.predict(X_lately) # predict the labels for the last forecast_out rows\nprint(forecast_set)\nprint()\nprint(f\"Doğruluk oranı (Accuracy) %.2f\" % accuracy)\nprint()\nprint(forecast_out) # print the predicted labels, accuracy, and forecast_out\n\ndf['Forecast'] = np.nan  # create a new column for the predicted labels","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:24:41.983559Z","iopub.execute_input":"2022-11-05T11:24:41.983979Z","iopub.status.idle":"2022-11-05T11:24:41.992089Z","shell.execute_reply.started":"2022-11-05T11:24:41.983944Z","shell.execute_reply":"2022-11-05T11:24:41.991178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Yeni bir model** <br>support vector regression","metadata":{}},{"cell_type":"code","source":"#support vector regression sigmoid\nclf = svm.SVR(kernel=\"sigmoid\") # kernel='poly' is the default kernel for SVR and is the best for non-linear data\nclf.fit(X_train, y_train) # fit the model to the training data (X_train and y_train) to train the model\naccuracy = clf.score(X_test, y_test)    # R^2 coefficient of determination, 1 is perfect prediction and 0 is no prediction at all (confidence)\nprint(f\"accuracy %.2f\" % accuracy) # print the accuracy of the model on the test data (X_test and y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:28:47.394539Z","iopub.execute_input":"2022-11-05T11:28:47.394974Z","iopub.status.idle":"2022-11-05T11:28:48.167212Z","shell.execute_reply.started":"2022-11-05T11:28:47.394932Z","shell.execute_reply":"2022-11-05T11:28:48.165966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#support vector regression\nclf = svm.SVR() # kernel='poly' is the default kernel for SVR and is the best for non-linear data\nclf.fit(X_train, y_train) # fit the model to the training data (X_train and y_train) to train the model\naccuracy = clf.score(X_test, y_test)    # R^2 coefficient of determination, 1 is perfect prediction and 0 is no prediction at all (confidence)\nprint(f\"accuracy %.2f\" % accuracy) # print the accuracy of the model on the test data (X_test and y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:28:32.799641Z","iopub.execute_input":"2022-11-05T11:28:32.800064Z","iopub.status.idle":"2022-11-05T11:28:33.294920Z","shell.execute_reply.started":"2022-11-05T11:28:32.800030Z","shell.execute_reply":"2022-11-05T11:28:33.293617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#support vector regression poly\nclf = svm.SVR(kernel=\"poly\") # kernel='poly' is the default kernel for SVR and is the best for non-linear data\nclf.fit(X_train, y_train) # fit the model to the training data (X_train and y_train) to train the model\naccuracy = clf.score(X_test, y_test)    # R^2 coefficient of determination, 1 is perfect prediction and 0 is no prediction at all (confidence)\nprint(f\"accuracy %.2f\" % accuracy) # print the accuracy of the model on the test data (X_test and y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:28:24.288892Z","iopub.execute_input":"2022-11-05T11:28:24.289315Z","iopub.status.idle":"2022-11-05T11:28:24.749628Z","shell.execute_reply.started":"2022-11-05T11:28:24.289280Z","shell.execute_reply":"2022-11-05T11:28:24.748704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#support vector machine rbf\nclf = svm.SVR(kernel='rbf')     # kernel='rbf' is the default kernel for SVM and is the best for non-linear data (default) and linear data\nclf.fit(X_train, y_train)      # fit the model to the training data (X_train and y_train) to train the model\naccuracy = clf.score(X_test, y_test)   # R^2 coefficient of determination, 1 is perfect prediction and 0 is no prediction at all (confidence)\nprint(f\"accuracy %.2f\" % accuracy)  # print the accuracy of the model on the test data (X_test and y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:29:37.175669Z","iopub.execute_input":"2022-11-05T11:29:37.176048Z","iopub.status.idle":"2022-11-05T11:29:37.675606Z","shell.execute_reply.started":"2022-11-05T11:29:37.176017Z","shell.execute_reply":"2022-11-05T11:29:37.674242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R^score <br>\nR², verilerin yerleştirilmiş regresyon hattına ne kadar yakın olduğunun istatistiksel bir ölçüsüdür. Ayrıca belirleme katsayısı veya çoklu regresyon için çoklu belirleme katsayısı olarak da bilinir. Daha basit bir dilde söylemek gerekirse R-kare, doğrusal regresyon modelleri için uygunluk ölçüsüdür.","metadata":{}},{"cell_type":"code","source":"#r2 score (coefficient of determination)\ny_true = [3, -0.5, 2, 7] \nfrom sklearn.metrics import r2_score    # import the r2_score from sklearn metrics module\nr2_score(y_true, y_pred)   # calculate the r2 score using the actual labels (y_test) and the predicted labels (y_pred)\nprint(r2_score()) # print the r2 score","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:34:17.827986Z","iopub.execute_input":"2022-11-05T11:34:17.828410Z","iopub.status.idle":"2022-11-05T11:34:17.853082Z","shell.execute_reply.started":"2022-11-05T11:34:17.828374Z","shell.execute_reply":"2022-11-05T11:34:17.851570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> MAE, MSE, RMSE, MAPE [Hakkında](https://forum.yazbel.com/t/mae-mse-rmse-mape-hakkinda/13701)","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# from seaborn import heatmap\n# from sklearn.model_selection import train_test_split\n# from sklearn.linear_model import LinearRegression\n# from sklearn.metrics import mean_squared_error, r2_score\n# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.neural_network import MLPRegressor\n# import matplotlib.style as mplstyle","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:36:15.343527Z","iopub.execute_input":"2022-11-05T11:36:15.343933Z","iopub.status.idle":"2022-11-05T11:36:15.349868Z","shell.execute_reply.started":"2022-11-05T11:36:15.343900Z","shell.execute_reply":"2022-11-05T11:36:15.348542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean absolute error\nfrom sklearn.metrics import mean_absolute_error # import the mean_absolute_error from sklearn metrics module\nmean_absolute_error(y_test, y_pred) # calculate the mean absolute error using the actual labels (y_test) and the predicted labels (y_pred)\nprint(mean_absolute_error) # print the mean absolute error","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:11:21.059736Z","iopub.execute_input":"2022-11-05T10:11:21.060077Z","iopub.status.idle":"2022-11-05T10:11:21.070801Z","shell.execute_reply.started":"2022-11-05T10:11:21.060047Z","shell.execute_reply":"2022-11-05T10:11:21.069682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#mean squared error\nfrom sklearn.metrics import mean_squared_error # import the mean_squared_error from sklearn metrics module\nmean_squared_error(y_test, y_pred) # calculate the mean squared error using the actual labels (y_test) and the predicted labels (y_pred)\nprint(mean_squared_error) # print the mean squared error\n\n#explained variance score\nfrom sklearn.metrics import explained_variance_score # import the explained_variance_score from sklearn metrics module\nexplained_variance_score(y_test, y_pred) # calculate the explained variance score using the actual labels (y_test) and the predicted labels (y_pred)\nprint(explained_variance_score) # print the explained variance score\n\n#mean squared log error\nfrom sklearn.metrics import mean_squared_log_error # import the mean_squared_log_error from sklearn metrics module\nmean_squared_log_error(y_test, y_pred) # calculate the mean squared log error using the actual labels (y_test) and the predicted labels (y_pred)\nprint(mean_squared_log_error) # print the mean squared log error\n\n#median absolute error\nfrom sklearn.metrics import median_absolute_error # import the median_absolute_error from sklearn metrics module\nmedian_absolute_error(y_test, y_pred) # calculate the median absolute error using the actual labels (y_test) and the predicted labels (y_pred)\nprint(median_absolute_error) # print the median absolute error\n\n#mean absolute percentage error\nfrom sklearn.metrics import mean_absolute_percentage_error # import the mean_absolute_percentage_error from sklearn metrics module\nmean_absolute_percentage_error(y_test, y_pred) # calculate the mean absolute percentage error using the actual labels (y_test) and the predicted labels (y_pred)\nprint(mean_absolute_percentage_error) # print the mean absolute percentage error","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:36:53.476870Z","iopub.execute_input":"2022-11-05T11:36:53.477327Z","iopub.status.idle":"2022-11-05T11:36:53.490519Z","shell.execute_reply.started":"2022-11-05T11:36:53.477287Z","shell.execute_reply":"2022-11-05T11:36:53.489115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#support vector machine (linear) classifier \nclf = LinearRegression(n_jobs=-1)\n# create the classifier object using the LinearRegression class\nclf.fit(X_train, y_train) # fit the model to the training data (X_train and y_train) to train the model\naccuracy = clf.score(X_test, y_test) # calculate the accuracy of the model using the test data (X_test and y_test)\nprint(f\"accuracy %.2f\"% accuracy) # print the accuracy","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:38:04.418797Z","iopub.execute_input":"2022-11-05T11:38:04.419202Z","iopub.status.idle":"2022-11-05T11:38:04.429050Z","shell.execute_reply.started":"2022-11-05T11:38:04.419169Z","shell.execute_reply":"2022-11-05T11:38:04.427937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast_set = clf.predict(X_lately) # predict the labels for the test data (X_lately) using the trained model\nprint(forecast_set, accuracy, forecast_out) # print the predicted labels (forecast_set), the accuracy (accuracy), and the forecast_out (forecast_out)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:38:08.707002Z","iopub.execute_input":"2022-11-05T11:38:08.707444Z","iopub.status.idle":"2022-11-05T11:38:08.715197Z","shell.execute_reply.started":"2022-11-05T11:38:08.707410Z","shell.execute_reply":"2022-11-05T11:38:08.713766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:38:14.546766Z","iopub.execute_input":"2022-11-05T11:38:14.547194Z","iopub.status.idle":"2022-11-05T11:38:14.552408Z","shell.execute_reply.started":"2022-11-05T11:38:14.547135Z","shell.execute_reply":"2022-11-05T11:38:14.550859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_date = df.iloc[-1].name # get the last date from the dataframe\nlast_unix = last_date.timestamp() # get the timestamp of the last date\none_day = 86400 # set the number of seconds in a day\nnext_unix = last_unix + one_day # get the timestamp of the next day\n\nfor i in forecast_set: # iterate through the forecast_set\n    next_date = datetime.datetime.fromtimestamp(next_unix) # get the date from the timestamp\n    next_unix += 86400 # add 86400 seconds to the timestamp\n    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i] # add the predicted label (i) to the dataframe\n\nfigure = plt.figure(figsize=(10, 10))\ndf['Close'].plot() # plot the Adj. Close column of the dataframe as a line plot\ndf['Forecast'].plot() # plot the Forecast column of the dataframe as a line plot\nplt.legend(loc=4) # set the legend of the plot\nplt.xlabel('Date') # set the x-axis label of the plot\nplt.ylabel('Price') # set the y-axis label of the plot\nplt.show() # show the plot\n","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:40:14.643510Z","iopub.execute_input":"2022-11-05T11:40:14.643954Z","iopub.status.idle":"2022-11-05T11:40:15.078014Z","shell.execute_reply.started":"2022-11-05T11:40:14.643918Z","shell.execute_reply":"2022-11-05T11:40:15.077215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving The model\nimport pickle #importing picke module\nwith open('linearregression.pickle','wb') as LRModel:\n    pickle.dump(clf,LRModel)\n    print(\"saved\")","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:41:09.685868Z","iopub.execute_input":"2022-11-05T11:41:09.686318Z","iopub.status.idle":"2022-11-05T11:41:09.694650Z","shell.execute_reply.started":"2022-11-05T11:41:09.686286Z","shell.execute_reply":"2022-11-05T11:41:09.693119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the model\npickle_in = open('linearregression.pickle','rb') # open the file linearregression.pickle in read binary mode\nclf = pickle.load(pickle_in) # load the classifier from the file\naccuracy = clf.score(X_test,y_test)\nprint(f\"accuracy %.2f\" %accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:43:41.119364Z","iopub.execute_input":"2022-11-05T11:43:41.119779Z","iopub.status.idle":"2022-11-05T11:43:41.129369Z","shell.execute_reply.started":"2022-11-05T11:43:41.119745Z","shell.execute_reply":"2022-11-05T11:43:41.128115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Follow on [Github](https://github.com/themanoftalent)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}