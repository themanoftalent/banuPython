{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#################################\n# IMPORT THE REQUIRED LIBRARIES #\n#################################\nimport pandas as pd\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport regex\nimport numpy as np\nimport datetime as dt\nimport dateutil.relativedelta\nimport statsmodels.api as sm\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils import class_weight\n\nfrom numpy.random import seed\nfrom keras.callbacks import EarlyStopping\n\nseed(1)\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ntf.random.set_seed(1234)\nrnd = np.random.RandomState(1)\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\n%matplotlib inline\n\nimport sklearn\nfrom numpy import interp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, roc_curve\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom mord import LogisticAT\nfrom sklearn.svm import LinearSVC, NuSVC, SVC\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nimport keras\n\nfrom numpy import interp\nfrom sklearn.metrics import auc, average_precision_score, confusion_matrix, roc_curve, precision_recall_curve\nfrom sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV, StratifiedKFold\n\n\nfrom sklearn.metrics import auc, f1_score\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.model_selection import StratifiedKFold\n","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:20:46.643903Z","iopub.execute_input":"2022-11-04T10:20:46.644297Z","iopub.status.idle":"2022-11-04T10:20:46.810875Z","shell.execute_reply.started":"2022-11-04T10:20:46.644265Z","shell.execute_reply":"2022-11-04T10:20:46.809721Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# pip install mord","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:20:42.479072Z","iopub.execute_input":"2022-11-04T10:20:42.479546Z","iopub.status.idle":"2022-11-04T10:20:42.485569Z","shell.execute_reply.started":"2022-11-04T10:20:42.479502Z","shell.execute_reply":"2022-11-04T10:20:42.484294Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"####################\n# READ THE DATASET #\n####################\n\ndf = pd.read_csv('../input/strokedatasetweather/stroke_data.csv')\n\n##########################\n# EDIT THE DATA FORMAT   #\n##########################","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:21:47.419336Z","iopub.execute_input":"2022-11-04T10:21:47.420697Z","iopub.status.idle":"2022-11-04T10:21:47.445029Z","shell.execute_reply.started":"2022-11-04T10:21:47.420642Z","shell.execute_reply":"2022-11-04T10:21:47.444110Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   gender   age  diabetes  hypertension  stroke  heart disease  \\\n0  Female  80.0         0             0       0              1   \n1  Female  54.0         0             0       0              0   \n2    Male  28.0         0             0       0              0   \n3  Female  36.0         0             0       0              0   \n4    Male  76.0         0             1       0              1   \n\n  smoking history    BMI  \n0           never  25.19  \n1             NaN    NaN  \n2           never    NaN  \n3         current  23.45  \n4         current  20.14  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>diabetes</th>\n      <th>hypertension</th>\n      <th>stroke</th>\n      <th>heart disease</th>\n      <th>smoking history</th>\n      <th>BMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>never</td>\n      <td>25.19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>current</td>\n      <td>23.45</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>76.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>current</td>\n      <td>20.14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['ONSET_Date'] = pd.to_datetime(df['ONSET_Date'])\ndf.Discharge_Plan_Modified_Rankin_Score = pd.to_numeric(df.Discharge_Plan_Modified_Rankin_Score, errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:21:59.565748Z","iopub.execute_input":"2022-11-04T10:21:59.566254Z","iopub.status.idle":"2022-11-04T10:21:59.677479Z","shell.execute_reply.started":"2022-11-04T10:21:59.566205Z","shell.execute_reply":"2022-11-04T10:21:59.675701Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'ONSET_Date'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3591135040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ONSET_Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ONSET_Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDischarge_Plan_Modified_Rankin_Score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDischarge_Plan_Modified_Rankin_Score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'ONSET_Date'"],"ename":"KeyError","evalue":"'ONSET_Date'","output_type":"error"}]},{"cell_type":"code","source":"\n\n\n\n##################################################################################\n# ADD ONE MORE PREDICTOR - a derivative variable called \"Aterogenic Index\" - IA) #\n# REMOVE INCORRECT VALUES                                                        #\n##################################################################################\n\ndf['IA'] = df['Lab_Investigation_low-density_lipoprotein']/(df['Lab_Investigation_TotalCholeserol']-df['Lab_Investigation_low-density_lipoprotein'])\n\ntemp = df[(df['Lab_Investigation_low-density_lipoprotein'].isna())|(df['Lab_Investigation_TotalCholeserol'].isna())]\ntemp = temp[['Lab_Investigation_low-density_lipoprotein','Lab_Investigation_TotalCholeserol']]\nind1 = temp[~temp.iloc[:,0].isna()].index \nind2 = temp[~temp.iloc[:,1].isna()].index\nai_ind = ind1.append(ind2)\n\nfor i in ai_ind:\n    df.loc[i,'IA'] = np.nan\n    \ndf['IA'].replace([np.inf, -np.inf], np.nan,inplace=True)\n\n#########################\n# ENCODE TIME INTERVALS #\n#########################\n\ndf['Day_Time'].replace({'Evening':1},inplace = True)\ndf['Day_Time'].replace({'Afternoon':2},inplace = True)\ndf['Day_Time'].replace({'Morning':3},inplace = True)\ndf['Day_Time'].replace({'Night':4},inplace = True)\n\n###############################\n# EDIT MISTYPING ERRORS       #\n###############################\n\nind = df[df['Lab_Investigation_TotalCholeserol']==4347].index\ndf.loc[ind,'Lab_Investigation_TotalCholeserol'] = 4.347\n\nind1 = df[df['Lab_Investigation_low-density_lipoprotein']==3157].index\ndf.loc[ind1,'Lab_Investigation_low-density_lipoprotein'] = 3.157","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:22:32.803988Z","iopub.execute_input":"2022-11-04T10:22:32.805184Z","iopub.status.idle":"2022-11-04T10:22:32.914828Z","shell.execute_reply.started":"2022-11-04T10:22:32.805139Z","shell.execute_reply":"2022-11-04T10:22:32.913311Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Lab_Investigation_low-density_lipoprotein'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/554612884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m##################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IA'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lab_Investigation_low-density_lipoprotein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lab_Investigation_TotalCholeserol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lab_Investigation_low-density_lipoprotein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lab_Investigation_low-density_lipoprotein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lab_Investigation_TotalCholeserol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Lab_Investigation_low-density_lipoprotein'"],"ename":"KeyError","evalue":"'Lab_Investigation_low-density_lipoprotein'","output_type":"error"}]},{"cell_type":"code","source":"data = df[df['ICH']==True].copy()\n\ndata.drop(columns=['ICH','Lab_Investigation_international_norm_ratio',\n       'Lab_Investigation_C-reactive protein',\n       'Lab_Investigation_TotalCholeserol',\n       'Lab_Investigation_low-density_lipoprotein',\n       'Lab_Investigation_POC_Random blood sugar',\n       'Lab_Investigation_Creatinine','IA','ONSET_Date'],inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T10:14:55.640166Z","iopub.execute_input":"2022-11-04T10:14:55.640584Z","iopub.status.idle":"2022-11-04T10:14:55.673449Z","shell.execute_reply.started":"2022-11-04T10:14:55.640551Z","shell.execute_reply":"2022-11-04T10:14:55.670695Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3198833220.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ICH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m data.drop(columns=['ICH','Lab_Investigation_international_norm_ratio',\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m'Lab_Investigation_C-reactive protein'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;34m'Lab_Investigation_TotalCholeserol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#########################################################################\n# 1.PROGNOSTICATION OF HS SEVERITY (NIHSS group) FROM INDIVIDUAL RISKS  #\n#########################################################################","metadata":{},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"data_nihss = data[~data.NIHSS_group.isna()]\ndata_nihss['NIHSS_group'] = np.where(data_nihss['Screening_tools_NIHSS']<=4,0,1)\ndata_nihss['NIHSS_group'].value_counts()","metadata":{},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":["1    47\n","0    38\n","Name: NIHSS_group, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"def build_barplot_nihss(df,feature,plot_title,xlabel):\n    \n    fig = plt.figure(figsize=(8,8))\n\n    g = sns.countplot(df[feature].replace({0:'No',1:'Yes'}), hue = df['NIHSS_group'])\n    plt.title(plot_title)\n    plt.xlabel(xlabel)\n    plt.ylabel('Counts')\n\n    leg = g.axes.get_legend()\n    new_title = 'NIHSS score'\n    leg.set_title(new_title)\n    new_labels = ['Less or equal to 4', 'More than 4']\n    for t, l in zip(leg.texts, new_labels): t.set_text(l)\n\n    for p in g.patches:\n        g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.5))\n\n    fig.show()\n    fig.savefig('ICH-NIHSS_{}_barplot.png'.format(feature))","metadata":{},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"build_barplot_nihss(data_nihss,'History_OldStroke','NIHSS group vs Old Stroke','Old Stroke')\nbuild_barplot_nihss(data_nihss,'History_DM','NIHSS group vs Diabetes Mellitus','Diabetes Mellitus')\nbuild_barplot_nihss(data_nihss,'History_HyperTension','NIHSS group vs Hyper Tension','Hyper Tension')\nbuild_barplot_nihss(data_nihss,'History_IschemicHeartDisease','NIHSS group vs Ischemic Heart Disease','Ischemic Heart Disease')\nbuild_barplot_nihss(data_nihss,'History_ArterFibrillation','NIHSS group vs Arter Fibrillation','Arter Fibrillation')\nbuild_barplot_nihss(data_nihss,'History_HyperLypidAemia','NIHSS group vs Hyper Lypid Aemia','Hyper Lypid Aemia')\n\nfig = plt.figure(figsize=(8,8))\n\ng = sns.countplot(data_nihss['Day_Time'].replace({1:'Evening',2:'Afternoon',3:'Morning',4:'Night'}), hue = data_nihss['NIHSS_group'])\nplt.title('NIHSS vs Day Time')\nplt.xlabel('History: Day Time')\nplt.ylabel('Counts')\n\nleg = g.axes.get_legend()\nnew_title = 'NIHSS score'\nleg.set_title(new_title)\nnew_labels = ['Less or equal to 4', 'More than 4']\nfor t, l in zip(leg.texts, new_labels): t.set_text(l)\n     \nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.2))\n    \nfig.show()\nfig.savefig('ICH-NIHSS_DAY_TIME_barplot.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_cols = ['TEMP', 'STP', 'WDSP', 'RH', 'HUMIDEX', 'TEMP1', 'TEMP2', 'TEMP3', 'TEMP4', 'TEMP5',\n                'TEMP6', 'TEMP7', 'STP1', 'STP2', 'STP3', 'STP4', 'STP5', 'STP6', 'STP7', 'WDSP1',\n                'WDSP2', 'WDSP3', 'WDSP4', 'WDSP5', 'WDSP6', 'WDSP7', 'RH1', 'RH2', 'RH3', 'RH4',\n                'RH5', 'RH6', 'RH7', 'HUMIDEX1', 'HUMIDEX2', 'HUMIDEX3', 'HUMIDEX4', 'HUMIDEX5',\n                'HUMIDEX6', 'HUMIDEX7', 'TDIF1', 'TDIF2', 'TDIF3', 'TDIF4', 'TDIF5', 'TDIF6', 'TDIF7',\n                'PDIF1', 'PDIF2', 'PDIF3', 'PDIF4', 'PDIF5', 'PDIF6', 'PDIF7', 'WDIF1', 'WDIF2', 'WDIF3',\n                'WDIF4', 'WDIF5', 'WDIF6', 'WDIF7', 'RHDIF1', 'RHDIF2', 'RHDIF3', 'RHDIF4', 'RHDIF5',\n                'RHDIF6', 'RHDIF7', 'HDIF1', 'HDIF2', 'HDIF3', 'HDIF4', 'HDIF5', 'HDIF6', 'HDIF7']\n\nnon_weather_cols = data_nihss.columns.difference(weather_cols)\n\ndata_nihss_nw = data_nihss[non_weather_cols]","metadata":{},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def get_outliers(df,col):\n    q1 = df[col].quantile(0.25) \n    q3 = df[col].quantile(0.75) \n    iqr = q3-q1\n    \n    return df[col][(df[col] > q3 + 1.5*iqr)|(df[col] < q1 - 1.5*iqr)].index","metadata":{},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"out = []\nfor col in ['BMI', 'DEMOGRAPHY_age','Day_Time']:\n    l = get_outliers(data_nihss_nw ,col)\n    print(col, l)\nout","metadata":{},"execution_count":94,"outputs":[{"name":"stdout","output_type":"stream","text":"BMI Int64Index([1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], dtype='int64')\n\nDEMOGRAPHY_age Int64Index([], dtype='int64')\n\nDay_Time Int64Index([], dtype='int64')\n"},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{}}]},{"cell_type":"code","source":"ind_bmi = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275]","metadata":{},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"data_nihss_nw.columns","metadata":{},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":["Index(['BMI', 'DEMOGRAPHY_age', 'DEMOGRAPHY_sex', 'Day_Time',\n","       'Discharge_Plan_Modified_Rankin_Score', 'History_ArterFibrillation',\n","       'History_DM', 'History_HyperLypidAemia', 'History_HyperTension',\n","       'History_IschemicHeartDisease', 'History_OldStroke', 'History_Smoking',\n","       'NIHSS_group', 'Screening_tools_NIHSS'],\n","      dtype='object')"]},"metadata":{}}]},{"cell_type":"code","source":"def get_weights(X,Y,cat=True):\n    ada = AdaBoostClassifier()\n    gb = GradientBoostingClassifier()\n    rf = RandomForestClassifier()\n    et = ExtraTreesClassifier()\n    \n    X_values = preprocessor.fit_transform(X)\n    \n    if (cat == True):\n        onehot_columns = list(preprocessor.transformers_[1][1]['onehot'].get_feature_names(cat_col))\n        numeric_features_list = list(num_col)\n        numeric_features_list.extend(onehot_columns)\n    else:\n        numeric_features_list = list(num_col)\n        \n    df_from_array_pipeline = pd.DataFrame(X_values, columns = numeric_features_list)\n    \n    ada.fit(X_values,Y)\n    gb.fit(X_values,Y)\n    rf.fit(X_values,Y)\n    et.fit(X_values,Y)\n\n    df_ada = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : ada.feature_importances_})\n    df_gb = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : gb.feature_importances_})\n    df_rf = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : rf.feature_importances_})\n    df_et = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : et.feature_importances_})\n    \n    result = pd.merge(df_ada[['feature','importance']], df_gb[['feature','importance']], on='feature')\n    result = pd.merge(result, df_rf[['feature','importance']], on='feature')\n    result = pd.merge(result, df_et[['feature','importance']], on='feature')\n    result['importance'] = result.mean(axis=1)\n    result = result.sort_values(by='importance', ascending = False)\n\n    return result[['feature','importance']]","metadata":{},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def draw_cv_roc_curve(classifiers, cv, X, y, title, filename, weights = False):\n    \"\"\"\n    Draw a Cross Validated PR Curve.\n    Keyword Args:\n        classifier: Classifier Object\n        cv: StratifiedKFold Object: (https://stats.stackexchange.com/questions/49540/understanding-stratified-cross-validation)\n        X: Feature Pandas DataFrame\n        y: Response Pandas Series\n\n    Largely taken from: https://stackoverflow.com/questions/29656550/how-to-plot-pr-curve-over-10-folds-of-cross-validation-in-scikit-learn\n    \"\"\"\n    \n    fig1 = plt.figure(figsize=[9,9])\n    ax1 = fig1.add_subplot(111,aspect = 'equal')\n\n    for clf in classifiers:\n        cv = StratifiedKFold(n_splits=10)\n        tprs = []\n        aucs = []\n\n        mean_fpr = np.linspace(0,1,100)\n        i = 1\n        for train, test in cv.split(X,y):\n            prediction = clf.fit(X[train],y[train]).predict_proba(X[test])\n\n            fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n            tprs.append(interp(mean_fpr, fpr, tpr))\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            i= i+1\n\n        plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n        mean_tpr = np.mean(tprs, axis=0)\n        mean_auc = auc(mean_fpr, mean_tpr)\n        plt.plot(mean_fpr, mean_tpr, color=np.random.rand(3,),\n                 label=r'{} Mean ROC (AUC = {:.3} )'.format(clf.__class__.__name__,mean_auc),lw=2, alpha=1)\n        \n    model = Sequential()\n    model.add(Dense(12, input_dim = len(X[0]), activation = 'relu'))\n    model.add(Dense(10, activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer = 'adam')        \n    \n    class_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(y), \n                y)\n\n    class_dict = {0:class_weights[0],1:class_weights[1]} \n            \n    for train, test in cv.split(X, y):\n        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0)\n        \n        if (weights == True):\n            model.fit(X[train],y[train],validation_data=(X[test],y[test]),class_weight=class_dict, verbose=0,epochs=500)\n        else:\n            model.fit(X[train],y[train],validation_data=(X[test],y[test]),verbose=0,epochs=500)\n            \n        prediction = model.predict(X[test])\n        \n        fpr, tpr, t = roc_curve(y[test], prediction)\n        tprs.append(interp(mean_fpr, fpr, tpr))\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        #  plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n        i= i+1\n\n    plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_auc = auc(mean_fpr, mean_tpr)\n    plt.plot(mean_fpr, mean_tpr, color=np.random.rand(3,),\n             label=r'{} Mean ROC (AUC = {:.3} )'.format('Neural Network',mean_auc),lw=2, alpha=1)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    \n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC')\n    plt.legend(loc=\"lower right\")\n   \n    plt.show()\n    fig1.savefig('ICH-{}.png'.format(filename))","metadata":{},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"def df_cat_nihss(df, scaler, outliers=False, weights=False):\n\n    X = data_nihss_nw.drop(columns=['NIHSS_group','Discharge_Plan_Modified_Rankin_Score','Screening_tools_NIHSS'])\n    Y = data_nihss_nw['NIHSS_group']\n    \n    if (outliers == True):\n        X.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)\n        Y.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)    \n    \n    cat_col = ['DEMOGRAPHY_sex','History_ArterFibrillation',\n               'History_DM','History_HyperLypidAemia','History_HyperTension','History_IschemicHeartDisease',\n               'History_OldStroke','History_Smoking']\n\n    num_col = X.columns.difference(cat_col)\n    \n    if scaler == 'standard':\n        sclr = StandardScaler()\n    else:\n        sclr = MinMaxScaler()\n        \n        \n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(drop='first')),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n            ('cat', categorical_transformer, cat_col)\n    ])\n    print(cat_col)\n    print(X.columns)\n    \n    ada = AdaBoostClassifier()\n    gb = GradientBoostingClassifier()\n    rf = RandomForestClassifier()\n    et = ExtraTreesClassifier()\n    \n    X_values = preprocessor.fit_transform(X)\n    \n    onehot_columns = list(preprocessor.transformers_[1][1]['onehot'].get_feature_names(cat_col))\n    numeric_features_list = list(num_col)\n    numeric_features_list.extend(onehot_columns)\n        \n    df_from_array_pipeline = pd.DataFrame(X_values, columns = numeric_features_list)\n    \n    ada.fit(X_values,Y)\n    gb.fit(X_values,Y)\n    rf.fit(X_values,Y)\n    et.fit(X_values,Y)\n\n    df_ada = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : ada.feature_importances_})\n    df_gb = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : gb.feature_importances_})\n    df_rf = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : rf.feature_importances_})\n    df_et = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : et.feature_importances_})\n    \n    result = pd.merge(df_ada[['feature','importance']], df_gb[['feature','importance']], on='feature')\n    result = pd.merge(result, df_rf[['feature','importance']], on='feature')\n    result = pd.merge(result, df_et[['feature','importance']], on='feature')\n    result['importance'] = result.mean(axis=1)\n    result = result.sort_values(by='importance', ascending = False)\n    feature_importances = result[['feature','importance']]\n    print(feature_importances.to_latex())\n    \n    fig = plt.figure(figsize=(15,6))\n\n    g = sns.barplot(x='feature',y='importance',data=feature_importances, palette = 'tab10')\n    g.set_xticklabels(rotation=90,labels = feature_importances['feature'])\n    g.set_title('Non-weather feature importances for NIHSS group')\n    plt.show()\n    \n            \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-NIHSS-FI-NW-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n    \n    feature_importances.to_csv('ICH-NIHSS-FI-NW-{}-{}-{}.csv'.format(o_str,w_str,scaler))\n    \n    fig.savefig(file_str)\n\n    to_keep = feature_importances.feature[:3]#['BMI', 'DEMOGRAPHY_age', 'Day_Time']\n    X = data_nihss_nw[to_keep]\n    Y = data_nihss_nw['NIHSS_group']\n    \n    \n    if (outliers == True):\n        X.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)\n        Y.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True) \n        \n    cat_col = []\n\n    num_col = X.columns.difference(cat_col)\n\n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n    ])\n\n\n    models = [\n        LogisticRegression(solver='lbfgs'), \n        RandomForestClassifier(n_estimators=300),\n        ExtraTreesClassifier(n_estimators=300),\n        AdaBoostClassifier(n_estimators=300),\n        SVC(kernel=\"linear\", C=0.025, probability = True)    \n    ]\n\n    X = preprocessor.fit_transform(X)\n    Y = np.array(Y)    \n        \n    cv = StratifiedKFold(n_splits=10,random_state=rnd)\n    \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'NIHSS-ROC-NW-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n        \n    draw_cv_roc_curve(models, cv, X, Y, title='ROC for NIHSS Group Prediction (non-weather predictors)',filename = file_str, weights = weights)","metadata":{},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"print('STANDARD SCALER, no weights')\ndf_cat_nihss(data_nihss_nw, 'standard', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, weights')\ndf_cat_nihss(data_nihss_nw, 'standard', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, no outliers')\ndf_cat_nihss(data_nihss_nw, 'standard', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('STANDARD SCALER, weights, no outliers')\ndf_cat_nihss(data_nihss_nw, 'standard', weights  = True, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, no weights')\ndf_cat_nihss(data_nihss_nw, 'minmax', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, weights')\ndf_cat_nihss(data_nihss_nw, 'minmax', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, no outliers')\ndf_cat_nihss(data_nihss_nw, 'minmax', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, weights, no outliers')\ndf_cat_nihss(data_nihss_nw, 'minmax', weights  = True, outliers  = True)\nprint('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(MinMaxScaler())","metadata":{},"execution_count":101,"outputs":[{"name":"stdout","output_type":"stream","text":"MinMaxScaler()\n"}]},{"cell_type":"code","source":"##################################################################################\n# 2.PORGNOSTICATION OF HS SEVERITY (NIHSS group) FROM THE FULL SET OF PREDICTORS #\n# (BOTH INDIVIDUAL RISKS AND WEATHER PARAMETERS)                                 #\n##################################################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = []\ntemp = data_nihss[['DEMOGRAPHY_age', 'BMI', 'TEMP', 'STP', 'WDSP', 'RH', 'HUMIDEX','Day_Time',\n       'TEMP1', 'TEMP2', 'STP1', 'STP2', 'WDSP1', 'WDSP2', 'RH1', 'RH2',\n       'HUMIDEX1', 'HUMIDEX2', 'TDIF1', 'TDIF2', 'PDIF1', 'PDIF2', 'WDIF1',\n       'WDIF2', 'RHDIF1', 'RHDIF2', 'HDIF1', 'HDIF2', 'NIHSS_group']]\nfor col in temp.columns:\n    l = get_outliers(temp,col)\n    print(col, l)\nout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_bmi = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275]\nind_wdsp = [1182, 1207, 1229, 1265]\nind_wdsp1 = [1123, 1229, 1259]\nind_wdsp2 = [1259, 1260]\nind_tdif1 = [1259, 1265]\nind_tdif2 = [1123, 1161, 1187, 1249, 1256, 1260, 1264]\nind_pdif1 = [1123, 1265]\nind_pdif2 = [1123, 1257]\nind_wdif1 = [1123]\nind_wdif2 = [1120, 1122, 1123, 1185, 1256]\nind_rhdif1 = [1146]\nind_rhdif2 = [1187, 1249, 1250, 1260, 1264]\nind_hdif1 = [1120, 1146, 1259]\nind_hdif2 = [1123, 1141, 1149, 1256, 1264]","metadata":{},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"ind_out = ind_bmi + ind_wdsp + ind_wdsp1 + ind_wdsp2 + ind_tdif1 + ind_tdif2 +ind_pdif1 + ind_pdif2 + ind_wdif1 + ind_wdif2 + ind_rhdif1 + ind_rhdif2 + ind_hdif1 + ind_hdif2\nind_out = pd.DataFrame(pd.Series(ind_out).value_counts())\nind_out = ind_out[ind_out.iloc[:,0]>1].index\nprint(ind_out)","metadata":{},"execution_count":104,"outputs":[{"name":"stdout","output_type":"stream","text":"Int64Index([1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,\n\n            1249],\n\n           dtype='int64')\n"}]},{"cell_type":"code","source":"def df_all_nihss(df, scaler, outliers=False, weights=False):\n    data_nihss_all = data_nihss[['DEMOGRAPHY_age', 'BMI', 'TEMP', 'STP', 'WDSP', 'RH', 'HUMIDEX','Day_Time',\n       'TEMP1', 'TEMP2', 'STP1', 'STP2', 'WDSP1', 'WDSP2', 'RH1', 'RH2',\n       'HUMIDEX1', 'HUMIDEX2', 'TDIF1', 'TDIF2', 'PDIF1', 'PDIF2', 'WDIF1',\n       'WDIF2', 'RHDIF1', 'RHDIF2', 'HDIF1', 'HDIF2', 'NIHSS_group']]\n    cor_matrix = data_nihss_all.corr().abs()\n    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n    data_nihss_all = data_nihss_all.drop(columns = to_drop)\n\n\n    \n    X = data_nihss_all.drop(columns=['NIHSS_group'])\n    Y = data_nihss_all['NIHSS_group']\n\n    if (outliers == True):\n        X.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)\n        Y.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)    \n\n    cat_col = []\n\n    num_col = X.columns.difference(cat_col)\n\n    if scaler == 'standard':\n        sclr = StandardScaler()\n    else:\n        sclr = MinMaxScaler()\n\n    \n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n    ])\n\n    ada = AdaBoostClassifier()\n    gb = GradientBoostingClassifier()\n    rf = RandomForestClassifier()\n    et = ExtraTreesClassifier()\n    \n    X_values = preprocessor.fit_transform(X)\n    \n    numeric_features_list = list(num_col)\n    \n    df_from_array_pipeline = pd.DataFrame(X_values, columns = numeric_features_list)\n    \n    ada.fit(X_values,Y)\n    gb.fit(X_values,Y)\n    rf.fit(X_values,Y)\n    et.fit(X_values,Y)\n\n    df_ada = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : ada.feature_importances_})\n    df_gb = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : gb.feature_importances_})\n    df_rf = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : rf.feature_importances_})\n    df_et = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : et.feature_importances_})\n    \n    result = pd.merge(df_ada[['feature','importance']], df_gb[['feature','importance']], on='feature')\n    result = pd.merge(result, df_rf[['feature','importance']], on='feature')\n    result = pd.merge(result, df_et[['feature','importance']], on='feature')\n    result['importance'] = result.mean(axis=1)\n    result = result.sort_values(by='importance', ascending = False)\n    feature_importances = result[['feature','importance']]\n    print(feature_importances.to_latex())\n    to_keep = list(feature_importances[feature_importances['importance']>0.04]['feature'])\n    print('Features to keep:', to_keep)\n    X = data_nihss_all[to_keep]\n    \n   # fig, axs = plt.subplots(1,2)\n    \n    fig = plt.figure(figsize=(15,6))\n\n    g = sns.barplot(x='feature',y='importance',data=feature_importances, palette = 'tab10')\n    g.set_xticklabels(rotation=90,labels = feature_importances['feature'])\n    g.set_title('All feature importances for NIHSS group')\n    plt.show()\n    \n        \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-NIHSS-FI-ALL-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n    feature_importances.to_csv('ICH-NIHSS-FI-ALL-{}-{}-{}.csv'.format(o_str,w_str,scaler))\n    \n    fig.savefig(file_str)\n\n    Y = data_nihss_all['NIHSS_group']\n    \n    if (outliers == True):\n        X.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)\n        Y.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)    \n\n    cat_col = []\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, X.columns),\n    ])\n\n\n    models = [\n        LogisticRegression(solver='lbfgs'), \n    #    LogisticRegressionCV(solver='lbfgs'),\n        RandomForestClassifier(n_estimators=300),\n        ExtraTreesClassifier(n_estimators=300),\n        AdaBoostClassifier(n_estimators=300),\n        SVC(kernel=\"linear\", C=0.025, probability = True)    \n    ]\n\n    print(X.columns)\n    #random_state = np.random.RandomState(0)\n    X = preprocessor.fit_transform(X)\n    Y = np.array(Y)\n    cv = StratifiedKFold(n_splits=10,random_state=rnd)\n          \n    file_str = 'ICH-NIHSS-ROC-ALL-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n        \n    draw_cv_roc_curve(models, cv, X, Y, title='ROC for NIHSS Group Prediction (all predictors)',filename = file_str, weights = weights)","metadata":{},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"print('STANDARD SCALER, no weights')\ndf_all_nihss(data_nihss, 'standard', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, weights')\ndf_all_nihss(data_nihss, 'standard', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, no outliers')\ndf_all_nihss(data_nihss, 'standard', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('STANDARD SCALER, weights, no outliers')\ndf_all_nihss(data_nihss, 'standard', weights  = True, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, no weights')\ndf_all_nihss(data_nihss, 'minmax', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, weights')\ndf_all_nihss(data_nihss, 'minmax', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, no outliers')\ndf_all_nihss(data_nihss, 'minmax', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, weights, no outliers')\ndf_all_nihss(data_nihss, 'minmax', weights  = True, outliers  = True)\nprint('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#######################################################################\n# 3.PROGNOSTICATION OF HS OUTCOMES (mRS group) FROM INDIVIDUAL RISKS  #\n#######################################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_mrs = data[~data.Discharge_Plan_Modified_Rankin_Score.isna()] #data.copy()\nind = data_mrs[data_mrs.NIHSS_group.isna()].index\ndata_mrs.drop(index = ind, inplace = True)\nind = data_mrs[data_mrs.Discharge_Plan_Modified_Rankin_Score==11].index\ndata_mrs.drop(index = ind, inplace = True)\n\ndata_mrs.Discharge_Plan_Modified_Rankin_Score.value_counts()\n\ndata_mrs['NIHSS_group'] = np.where(data_mrs['Screening_tools_NIHSS']<=4,0,1)\ndata_mrs['NIHSS_group'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_mrs['MRS_group'] = np.where(data_mrs['Discharge_Plan_Modified_Rankin_Score']<=3,0,1)\ndata_mrs['MRS_group'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_barplot_mrs(df,feature,plot_title,xlabel):\n    \n    fig = plt.figure(figsize=(8,8))\n\n    g = sns.countplot(df[feature].replace({0:'No',1:'Yes'}), hue = df['MRS_group'])\n    plt.title(plot_title)\n    plt.xlabel(xlabel)\n    plt.ylabel('Counts')\n\n    leg = g.axes.get_legend()\n    new_title = 'MRS score'\n    leg.set_title(new_title)\n    new_labels = ['Less or equal to 3', 'More than 3']\n    for t, l in zip(leg.texts, new_labels): t.set_text(l)\n\n    for p in g.patches:\n        g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.5))\n\n    fig.show()\n    fig.savefig('ICH-MRS_{}_barplot.png'.format(feature))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_barplot_mrs(data_mrs,'History_OldStroke','MRS group vs Old Stroke','Old Stroke')\nbuild_barplot_mrs(data_mrs,'History_DM','MRS group vs Diabetes Mellitus','Diabetes Mellitus')\nbuild_barplot_mrs(data_mrs,'History_HyperTension','MRS group vs Hyper Tension','Hyper Tension')\nbuild_barplot_mrs(data_mrs,'History_IschemicHeartDisease','MRS group vs Ischemic Heart Disease','Ischemic Heart Disease')\nbuild_barplot_mrs(data_mrs,'History_ArterFibrillation','MRS group vs Arter Fibrillation','Arter Fibrillation')\nbuild_barplot_mrs(data_mrs,'History_HyperLypidAemia','MRS group vs Hyper Lypid Aemia','Hyper Lypid Aemia')\n\nfig = plt.figure(figsize=(8,8))\n\ng = sns.countplot(data_mrs['Day_Time'].replace({1:'Evening',2:'Afternoon',3:'Morning',4:'Night'}), hue = data_mrs['MRS_group'])\nplt.title('MRS vs Day Time')\nplt.xlabel('History: Day Time')\nplt.ylabel('Counts')\n\nleg = g.axes.get_legend()\nnew_title = 'MRS score'\nleg.set_title(new_title)\nnew_labels = ['Less or equal to 3', 'More than 3']\nfor t, l in zip(leg.texts, new_labels): t.set_text(l)\n     \nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.2))\n    \nfig.show()\nfig.savefig('ICH-MRS_DAY_TIME_barplot.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_weather_cols = data_mrs.columns.difference(weather_cols)\ndata_mrs_nw = data_mrs[non_weather_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_cat_mrs(df, scaler, outliers=False, weights=False):\n\n    X = data_mrs_nw.drop(columns=['NIHSS_group','MRS_group','Discharge_Plan_Modified_Rankin_Score'])\n    Y = data_mrs_nw['MRS_group']\n    \n    \n    if (outliers == True):\n        X.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)\n        Y.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)    \n    \n    cat_col = ['DEMOGRAPHY_sex','History_ArterFibrillation',\n               'History_DM','History_HyperLypidAemia','History_HyperTension','History_IschemicHeartDisease',\n               'History_OldStroke','History_Smoking']\n\n    num_col = X.columns.difference(cat_col)\n    \n    if scaler == 'standard':\n        sclr = StandardScaler()\n    else:\n        sclr = MinMaxScaler()\n        \n        \n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(drop='first')),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n            ('cat', categorical_transformer, cat_col)\n    ])\n    print(cat_col)\n    print(X.columns)\n    \n    ada = AdaBoostClassifier()\n    gb = GradientBoostingClassifier()\n    rf = RandomForestClassifier()\n    et = ExtraTreesClassifier()\n    \n    X_values = preprocessor.fit_transform(X)\n    \n    onehot_columns = list(preprocessor.transformers_[1][1]['onehot'].get_feature_names(cat_col))\n    numeric_features_list = list(num_col)\n    numeric_features_list.extend(onehot_columns)\n        \n    df_from_array_pipeline = pd.DataFrame(X_values, columns = numeric_features_list)\n    \n    ada.fit(X_values,Y)\n    gb.fit(X_values,Y)\n    rf.fit(X_values,Y)\n    et.fit(X_values,Y)\n\n    df_ada = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : ada.feature_importances_})\n    df_gb = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : gb.feature_importances_})\n    df_rf = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : rf.feature_importances_})\n    df_et = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : et.feature_importances_})\n    \n    result = pd.merge(df_ada[['feature','importance']], df_gb[['feature','importance']], on='feature')\n    result = pd.merge(result, df_rf[['feature','importance']], on='feature')\n    result = pd.merge(result, df_et[['feature','importance']], on='feature')\n    result['importance'] = result.mean(axis=1)\n    result = result.sort_values(by='importance', ascending = False)\n    feature_importances = result[['feature','importance']]\n    print(feature_importances.to_latex())\n    \n    fig = plt.figure(figsize=(15,6))\n\n    g = sns.barplot(x='feature',y='importance',data=feature_importances, palette = 'tab10')\n    g.set_xticklabels(rotation=90,labels = feature_importances['feature'])\n    g.set_title('Non-weather feature importances for MRS group')\n    plt.show()\n    \n            \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-MRS-FI-NW-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n    \n    fig.savefig(file_str)\n    feature_importances.to_csv('ICH-MRS-FI-NW-{}-{}-{}.csv'.format(o_str,w_str,scaler))\n\n    to_keep = feature_importances.feature[:3]#['BMI', 'DEMOGRAPHY_age', 'Day_Time']\n    \n  #  print(X.shape, Y.shape)\n    \n    X = data_mrs_nw[to_keep]\n    Y = data_mrs_nw['MRS_group']\n  #  print(X.shape, Y.shape)\n    \n    if (outliers == True):\n        X.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)\n        Y.drop(index = [1125, 1150, 1153, 1182, 1196, 1255, 1263, 1275], inplace = True)    \n        \n    cat_col = []\n\n    num_col = X.columns.difference(cat_col)\n\n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n    ])\n\n\n    models = [\n        LogisticRegression(solver='lbfgs'), \n        RandomForestClassifier(n_estimators=300),\n        ExtraTreesClassifier(n_estimators=300),\n        AdaBoostClassifier(n_estimators=300),\n        SVC(kernel=\"linear\", C=0.025, probability = True)    \n    ]\n\n    X = preprocessor.fit_transform(X)\n    Y = np.array(Y)\n    cv = StratifiedKFold(n_splits=10,random_state=rnd)\n    print(X.shape, Y.shape)\n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'MRS-ROC-NW-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n    print(X.shape, Y.shape)    \n    draw_cv_roc_curve(models, cv, X, Y, title='ROC for MRS Group Prediction (non-weather predictors)',filename = file_str, weights = weights)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('STANDARD SCALER, no weights')\ndf_cat_mrs(data_mrs_nw, 'standard', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, weights')\ndf_cat_mrs(data_mrs_nw, 'standard', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, no outliers')\ndf_cat_mrs(data_mrs_nw, 'standard', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('STANDARD SCALER, weights, no outliers')\ndf_cat_mrs(data_mrs_nw, 'standard', weights  = True, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, no weights')\ndf_cat_mrs(data_mrs_nw, 'minmax', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, weights')\ndf_cat_mrs(data_mrs_nw, 'minmax', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, no outliers')\ndf_cat_mrs(data_mrs_nw, 'minmax', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, weights, no outliers')\ndf_cat_mrs(data_mrs_nw, 'minmax', weights  = True, outliers  = True)\nprint('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################\n# 4.PORGNOSTICATION OF HS OUTCOMES (mRS group) FROM THE FULL SET OF PREDICTORS #\n# (BOTH INDIVIDUAL RISKS AND WEATHER PARAMETERS)                               #\n################################################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_all_mrs(df, scaler, outliers=False, weights=False):\n    data_mrs_all = data_mrs[['DEMOGRAPHY_age', 'BMI', 'TEMP', 'STP', 'WDSP', 'RH', 'HUMIDEX','Day_Time',\n       'TEMP1', 'TEMP2', 'STP1', 'STP2', 'WDSP1', 'WDSP2', 'RH1', 'RH2','Screening_tools_NIHSS',\n       'HUMIDEX1', 'HUMIDEX2', 'TDIF1', 'TDIF2', 'PDIF1', 'PDIF2', 'WDIF1',\n       'WDIF2', 'RHDIF1', 'RHDIF2', 'HDIF1', 'HDIF2', 'MRS_group']]\n    cor_matrix = data_mrs_all.corr().abs()\n    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n    data_mrs_all = data_mrs_all.drop(columns = to_drop)\n    \n    X = data_mrs_all.drop(columns=['MRS_group'])\n    Y = data_mrs_all['MRS_group']\n\n    if (outliers == True):\n        X.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)\n        Y.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)    \n\n    cat_col = []\n\n    num_col = X.columns.difference(cat_col)\n\n    if scaler == 'standard':\n        sclr = StandardScaler()\n    else:\n        sclr = MinMaxScaler()\n\n    \n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', sclr),\n    ])\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, num_col),\n    ])\n\n    ada = AdaBoostClassifier()\n    gb = GradientBoostingClassifier()\n    rf = RandomForestClassifier()\n    et = ExtraTreesClassifier()\n    \n    X_values = preprocessor.fit_transform(X)\n    \n    numeric_features_list = list(num_col)\n    \n    df_from_array_pipeline = pd.DataFrame(X_values, columns = numeric_features_list)\n    \n    ada.fit(X_values,Y)\n    gb.fit(X_values,Y)\n    rf.fit(X_values,Y)\n    et.fit(X_values,Y)\n\n    df_ada = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : ada.feature_importances_})\n    df_gb = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : gb.feature_importances_})\n    df_rf = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : rf.feature_importances_})\n    df_et = pd.DataFrame({'feature':np.array(numeric_features_list), 'importance' : et.feature_importances_})\n    \n    result = pd.merge(df_ada[['feature','importance']], df_gb[['feature','importance']], on='feature')\n    result = pd.merge(result, df_rf[['feature','importance']], on='feature')\n    result = pd.merge(result, df_et[['feature','importance']], on='feature')\n    result['importance'] = result.mean(axis=1)\n    result = result.sort_values(by='importance', ascending = False)\n    feature_importances = result[['feature','importance']]\n    print(feature_importances.to_latex())\n    to_keep = list(feature_importances[feature_importances['importance']>0.04]['feature'])\n    print('Features to keep:', to_keep)\n    X = data_mrs_all[to_keep]\n        \n    fig = plt.figure(figsize=(15,6))\n\n    g = sns.barplot(x='feature',y='importance',data=feature_importances, palette = 'tab10')\n    g.set_xticklabels(rotation=90,labels = feature_importances['feature'])\n    g.set_title('All feature importances for MRS group')\n    plt.show()\n    \n        \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-MRS-FI-ALL-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n        \n    fig.savefig(file_str)\n    \n    feature_importances.to_csv('ICH-MRS-FI-ALL-{}-{}-{}.csv'.format(o_str,w_str,scaler))\n\n\n    Y = data_mrs_all['MRS_group']\n    \n    if (outliers == True):\n        X.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)\n        Y.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)    \n\n    cat_col = []\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, X.columns),\n    ])\n\n\n    models = [\n        LogisticRegression(solver='lbfgs'), \n    #    LogisticRegressionCV(solver='lbfgs'),\n        RandomForestClassifier(n_estimators=300),\n        ExtraTreesClassifier(n_estimators=300),\n        AdaBoostClassifier(n_estimators=300),\n        SVC(kernel=\"linear\", C=0.025, probability = True)    \n    ]\n\n    print(X.columns)\n    X = preprocessor.fit_transform(X)\n    Y = np.array(Y)\n    cv = StratifiedKFold(n_splits=10,random_state=rnd)\n          \n    file_str = 'ICH-MRS-ROC-ALL-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n        \n   \n    to_keep = list(feature_importances[feature_importances['importance']>0.04]['feature'])\n\n    fig1 = plt.figure(figsize=[12,12])\n    ax1 = fig1.add_subplot(111,aspect = 'equal')\n\n    model = Sequential()\n    model.add(Dense(12, input_dim = 1, activation = 'relu'))\n    model.add(Dense(10, activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer = 'adam')        \n    \n    data_tmp = data_mrs.copy()\n    if (outliers == True):\n        data_tmp.drop(index = [1123, 1259, 1256, 1264, 1265, 1260, 1229, 1146, 1187, 1182, 1120,1249], inplace = True)\n    \n    df_roc = pd.DataFrame([])\n        \n    for feature in to_keep:\n        X = data_tmp[feature]\n        Y = data_tmp['MRS_group']\n\n        numerical_transformer = Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')),\n            ('scaler', sclr),\n        ])\n\n        X = np.array(X)\n\n        X = numerical_transformer.fit_transform(X.reshape(-1, 1))\n        Y = np.array(Y)\n\n        cv = StratifiedKFold(n_splits=10)\n        tprs = []\n        aucs = []\n\n\n        class_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(Y), \n                Y)\n\n        class_dict = {0:class_weights[0],1:class_weights[1]} \n     \n        mean_fpr = np.linspace(0,1,100)\n        i = 1\n        for train, test in cv.split(X,Y):\n            if (weights == True):\n                model.fit(X[train],Y[train],validation_data=(X[test],Y[test]),class_weight=class_dict, verbose=0,epochs=500)\n            else:\n                model.fit(X[train],Y[train],validation_data=(X[test],Y[test]),verbose=0,epochs=500)\n\n            prediction = model.predict(X[test])\n\n            fpr, tpr, t = roc_curve(Y[test], prediction)\n            tprs.append(interp(mean_fpr, fpr, tpr))\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            i= i+1\n\n        plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n        mean_tpr = np.mean(tprs, axis=0)\n        mean_auc = auc(mean_fpr, mean_tpr)\n        plt.plot(mean_fpr, mean_tpr, color=np.random.rand(3,),\n                 label=r'{} (AUC = {:.3} )'.format(feature,mean_auc),lw=2, alpha=1)\n        df_roc = df_roc.append(pd.Series([feature,mean_auc]),ignore_index = True)\n    \n    df_roc.columns = ['Feature','ROC']\n    \n    df_roc.sort_values(by=['ROC'], inplace = True)\n    \n    print(df_roc.to_latex())\n    \n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curves for MRS prediction')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-ROC-MRS-all-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n        \n    df_roc.to_csv('ICH-ROC-MRS-all-ROC-{}-{}-{}.csv')\n    fig1.savefig(file_str)\n    \n    selected_features = df_roc.Feature[:3]\n\n    all_features = to_keep\n    print('Selected features:',selected_features)\n    print('All features:',all_features)\n\n    fig1 = plt.figure(figsize=[12,12])\n    ax1 = fig1.add_subplot(111,aspect = 'equal')\n\n\n\n    for feature in [selected_features, all_features]:\n        X = data_tmp[feature]\n        Y = data_tmp['MRS_group']\n\n        model = Sequential()\n        model.add(Dense(12, input_dim = X.shape[1], activation = 'relu'))\n        model.add(Dense(10, activation = 'relu'))\n        model.add(Dense(1, activation = 'sigmoid'))\n        model.compile(loss='binary_crossentropy', optimizer = 'adam')        \n\n        cv = StratifiedKFold(n_splits=10)\n        tprs = []\n        aucs = []\n\n        numerical_transformer = Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')),\n            ('scaler', sclr),\n        ])\n\n        X = np.array(X)\n\n        X = numerical_transformer.fit_transform(X)\n        Y = np.array(Y)\n\n        mean_fpr = np.linspace(0,1,100)\n        i = 1\n        for train, test in cv.split(X,Y):\n            \n            if (weights == True):\n                model.fit(X[train],Y[train],validation_data=(X[test],Y[test]),class_weight=class_dict, verbose=0,epochs=500)\n            else:\n                model.fit(X[train],Y[train],validation_data=(X[test],Y[test]),verbose=0,epochs=500)\n\n            prediction = model.predict(X[test])\n\n            fpr, tpr, t = roc_curve(Y[test], prediction)\n            tprs.append(interp(mean_fpr, fpr, tpr))\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            i= i+1\n\n        plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n        mean_tpr = np.mean(tprs, axis=0)\n        mean_auc = auc(mean_fpr, mean_tpr)\n\n        if (len(X[0])==3):\n            label = r'{} (AUC = {:.3} )'.format(selected_features, mean_auc)\n        else:\n            label = r'All Significant Features (AUC = {:.3} )'.format(mean_auc)\n\n        plt.plot(mean_fpr, mean_tpr, color=np.random.rand(3,),\n                 label=label,lw=2, alpha=1)\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curves for MRS prediction')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    if (weights == True):\n        w_str = 'weights'\n    else:\n        w_str = 'NOweights'\n        \n    if (outliers == True):\n        o_str = 'out'\n    else:\n        o_str = 'NOout'\n        \n    file_str = 'ICH-ROC-MRS-2-{}-{}-{}.png'.format(o_str,w_str,scaler)    \n    \n    fig1.savefig(file_str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('STANDARD SCALER, no weights')\ndf_all_mrs(data_mrs, 'standard', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, weights')\ndf_all_mrs(data_mrs, 'standard', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('STANDARD SCALER, no outliers')\ndf_all_mrs(data_mrs, 'standard', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('STANDARD SCALER, weights, no outliers')\ndf_all_mrs(data_mrs, 'standard', weights  = True, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, no weights')\ndf_all_mrs(data_mrs, 'minmax', weights  = False, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, weights')\ndf_all_mrs(data_mrs, 'minmax', weights  = True, outliers  = False)\nprint('\\n')\n\nprint('MINMAX SCALER, no outliers')\ndf_all_mrs(data_mrs, 'minmax', weights  = False, outliers  = True)\nprint('\\n')\n\nprint('MINMAX SCALER, weights, no outliers')\ndf_all_mrs(data_mrs, 'minmax', weights  = True, outliers  = True)\nprint('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}