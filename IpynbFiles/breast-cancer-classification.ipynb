{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"88e3016d-f575-dc76-07e5-68ef94d3e67a","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ndataset = pd.read_csv(\"../input/data.csv\")\ndataset[['diagnosis']].groupby('diagnosis').size()","metadata":{"_cell_guid":"ad11c780-8fe7-4161-b8e1-cf878958b521","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[dataset['diagnosis'] != 'M'].head(5)","metadata":{"_cell_guid":"5b4f64df-de89-066b-06bc-cc3e0b92edb0","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[(dataset['diagnosis'] != 'M') & (dataset['id'] < 8510653) ].head(5)","metadata":{"_cell_guid":"39e6825d-e4c7-4da5-d6a0-64cd2c334a00","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset.columns)","metadata":{"_cell_guid":"f4b63886-4570-e1aa-320d-5732d37462de","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainingDataSet, evaluationDataSet = train_test_split(dataset, test_size = 0.2)\nprint(\n    \" Training data set : \",\n     trainingDataSet.shape,\n     \"\\n\",\n    \"Evalutation data set : \",\n    evaluationDataSet.shape\n)","metadata":{"_cell_guid":"5b466979-46e8-c293-1d5b-2c1685132a42","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nclassifier = svm.SVC(gamma=0.001, C=100.);\n\n\nevaluationDataSetCopy = evaluationDataSet.copy()\ntrainingDataSetCopy = trainingDataSet.copy()\n#trainingDataSetLabels = classifier.fit(trainingDataSet['diagnosis'])\ntrainingDataSetLabels = trainingDataSet[['diagnosis']];\n\nevaluationDataSetCopy.pop('id')\nevaluationDataSetCopy.pop('diagnosis')\nevaluationDataSetCopy.pop('Unnamed: 32')\n\ntrainingDataSetCopy.pop('id')\ntrainingDataSetCopy.pop('diagnosis')\ntrainingDataSetCopy.pop('Unnamed: 32')\n\n\n\ntrainingDataSetUnlabeled = trainingDataSetCopy\nevaluationDataSetUnlabeled = evaluationDataSetCopy;\n\nevaluation = {\n    'data': evaluationDataSet.as_matrix(),\n    'target': evaluationDataSet.as_matrix(columns=['diagnosis']).flatten(),\n    'unlabeled': evaluationDataSetUnlabeled.as_matrix(),\n}\ntraining = {\n    'data': trainingDataSet.as_matrix(),\n    'target': trainingDataSetLabels.as_matrix(columns=['diagnosis']).flatten(),\n    'unlabeled': trainingDataSetUnlabeled.as_matrix(),\n}\n\nclassifier.fit(training['unlabeled'], training['target'])\n\nprediction = classifier.predict(evaluation['unlabeled'][0].reshape(1, -1))[0];\nactualValue = evaluation['target'][0]\n\nprint(\"Predicted tumour type : \", prediction,\" Actual tumour type : \", actualValue);\nprint( \"ðŸŽ‰ Prediction is correct ! ðŸŽ‰\" if (prediction == actualValue ) else \"ðŸ˜ž, I'm still not smart enough !\" );","metadata":{"_cell_guid":"04083691-dc6d-8e23-3c39-f5bfa7d23b1c","_active":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\npredictions = classifier.predict(evaluation['unlabeled'])\nactualValues = evaluation['target']\n\naccuracyScore= accuracy_score(actualValues, predictions);\nclassification_report = classification_report(actualValues, predictions);\nprint(\"Accuracy Score = \", round(accuracyScore*100),\"%\");\nprint(\"Classification Report = \");\nprint(classification_report);\nprint('\\nConfussion matrix:\\n',confusion_matrix(actualValues, predictions));","metadata":{"_cell_guid":"91923f50-a03f-fc15-2823-882d158be7d1","_active":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"b40e73d1-e084-a6fc-2b8f-3622d88eac22","_active":false},"execution_count":null,"outputs":[]}]}